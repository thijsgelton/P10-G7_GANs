{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CGCV192014B",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thijsgelton/P10-G7_GANs/blob/main/P10-G7_GANs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqnyegcdIq0W"
      },
      "source": [
        "```\n",
        "SOW-MKI95 Computer Graphics & Computer Vision\n",
        "Generative adversarial networks\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKchsx6FIsFp"
      },
      "source": [
        "```\n",
        "Group number: ...\n",
        "Student 1 name/number: ...\n",
        "Student 2 name/number: ...\n",
        "...\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWky4cKAItZu"
      },
      "source": [
        "In this lab, you will reimplement the DCGAN from the Gluon tutorial, convert it to a WGAN and compare their results after training them on different datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2TLqfjFIuuC"
      },
      "source": [
        "### Task 1 (33 points):\n",
        "\n",
        "Reimplement the DCGAN from the Gluon tutorial in this notebook. You can find the Gluon tutorial [here](https://gluon.mxnet.io/chapter14_generative-adversarial-networks/dcgan.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBFUuzdVIpQq"
      },
      "source": [
        "# Your code here..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5atO6OwWI4Yh"
      },
      "source": [
        "### Task 2 (33 points):\n",
        "\n",
        "Convert the DCGAN to a WGAN.\n",
        "\n",
        "You can refer to [the WGAN paper](https://arxiv.org/abs/1701.07875) and/or the below notes.\n",
        "\n",
        "The paper introduces a new loss function for both the discriminator and the generator. Using this loss function instead of binary cross entropy results in a more stable convergence of the GAN.\n",
        "\n",
        "#### Loss\n",
        "\n",
        "Let’s compare the binary cross-entropy loss function (the function that that we are currently using to train the discriminator and generator of the DCGAN) to the Wasserstein loss function.\n",
        "\n",
        "First, the Wasserstein loss requires that we use yi=1 and yi=-1 as labels, rather than 1 and 0. We also remove the sigmoid activation from the final layer of the discriminator, so that predictions pi are no longer constrained to fall in the range [0,1], but instead can now be any number in the range [–∞, ∞]. For this reason, the discriminator in a WGAN is usually referred to as a critic. The Wasserstein loss function is then defined as follows:\n",
        "\n",
        "$$-\\frac{1}{n} \\sum_{i=1}^{n}\\left(y_{i} p_{i}\\right)$$\n",
        "\n",
        "To train the WGAN critic D, we calculate the loss when comparing predictions for a real images pi=D(xi) to the response yi=1 and predictions for generated images pi=D(G(zi)) to the response yi=-1. Therefore for the WGAN critic, minimizing the loss function can be written as follows:\n",
        "\n",
        "$$\\min _{D}-\\left(\\mathbb{E}_{x \\sim p_{X}}[D(x)]-\\mathbb{E}_{z \\sim p_{Z}}[D(G(z))]\\right)$$\n",
        "\n",
        "In other words, the WGAN critic tries to maximise the difference between its predictions for real images and generated images, with real images scoring higher. To train the WGAN generator, we calculate the loss when comparing predictions for generated images pi=D(G(zi)) to the response yi=1. Therefore for the WGAN generator, minimizing the loss function can be written as follows:\n",
        "\n",
        "$$\\min _{G}-\\left(\\mathbb{E}_{z \\sim p_{Z}}[D(G(z))]\\right)$$\n",
        "\n",
        "#### Constraints\n",
        "\n",
        "For the Wasserstein loss function to work, we also need to place an additional constraint on the critic. Specifically, it is required that the critic is a 1-Lipschitz continuous function. Let’s pick this apart to understand what it means in more detail. The critic is a function D that converts an image into a prediction. We say that this function is 1-Lipschitz if it satisfies the following inequality for any two input images, \\( x_1 \\) and \\( x_2 \\):\n",
        "\n",
        "$$ \\vert\\frac{D(x_1)-D(x_2)\\vert}{\\vert x_1-x_2\\vert}\\leq1 $$\n",
        "\n",
        "Essentially, we require a limit on the rate at which the predictions of the critic can change between two images (i.e., the absolute value of the gradient must be at most 1 everywhere).\n",
        "\n",
        "It is possible to enforce the Lipschitz constraint by clipping the weights of the critic to lie within a small range, [–0.01, 0.01], after each training batch.\n",
        "\n",
        "#### Training\n",
        "\n",
        "When using the Wasserstein loss function, we should train the critic to convergence to ensure that the gradients for the generator update are accurate. This is in contrast to a standard GAN, where it is important not to let the discriminator get too strong, to avoid vanishing gradients.\n",
        "\n",
        "Therefore, using the Wasserstein loss removes one of the key difficulties of training GANs—how to balance the training of the discriminator and generator. With WGANs, we can simply train the critic several times between generator updates, to ensure it is close to convergence. A typical ratio used is five critic updates to one generator update."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsIKJumoI39f"
      },
      "source": [
        "# Your code here..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fCSnwZHJGiQ"
      },
      "source": [
        "### Task 3 (33 points):\n",
        "\n",
        "Compare their results of the DCGAN and the WGAN after training them on different datasets (at least three). You are free to select which datasets to use (it would be easier if you use relatively small datasets). For example, you can use MNIST and Fashion-MNIST datasets (available from Gluon) or anime characters and pokemons datasets (several versions can be found on GitHub)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgnpFvPuKSf4"
      },
      "source": [
        "# Your code here..."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}